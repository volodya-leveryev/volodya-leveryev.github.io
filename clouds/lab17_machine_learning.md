# Машинное обучение в облачных сервисах

## Цель
Рассмотреть пример применения облачных сервисов для дообучения моделей искусственной нейронной сети и развертывания готового приложения.

## Теоретическая часть

*Kaggle* — это онлайн-платформа для работы с данными, которая объединяет специалистов в области машинного обучения, анализа данных и искусственного интеллекта со всего мира. На текущий момент платформа Kaggle представляет возможность бесплатно использовать в течение 30 часов в неделю GPU типа Nvidia Tesla P100.

*Google Colab* (полное название — Google Colaboratory) — это бесплатная облачная платформа от Google, предоставляющая возможность писать и запускать код на Python в браузере, без необходимости установки ПО на компьютер.

*Hugging Face* — это стартап который стремится упростить процессы разработки, обучения, публикации и использования моделей машинного обучения, особенно в области NLP (Natural Language Processing), CV (Computer Vision) и Audio AI. Платформа ориентирована на открытость, удобство и сообщество.

Основные компоненты платформы Hugging Face:
* *Models* — хранилище предобученных моделей от сообщества и организаций.
* *Datasets* — хранилище тысяч датасетов: от популярных (IMDB, COCO, LibriSpeech) до редких и специфичных.
* *Spaces* — облачная платформа, для развертывания и демонстрации моделей машинного обучения и веб-приложений.
* *Transformers* — Python-библиотека с реализациями сотен современных моделей трансформеров.
* *Inference Endpoints* — Хостинг моделей в облаке с REST API.

*Hugging Face Spaces* поддерживает развертывание Docker-контейнеров и фреймворки `Gradio` и `Streamlit`.

*Gradio* — это фреймворк на Python для быстрого создания интерактивных веб-интерфейсов к моделям машинного обучения. Он позволяет всего в несколько строк кода развернуть веб-приложение, где пользователи могут загружать изображения, вводить текст или аудио и получать ответы от модели в реальном времени.

Gradio часто используют для демо, тестирования и визуализации ML-моделей без необходимости писать фронтенд-код. Gradio чаще всего выбирают за его простоту, особенно на этапе прототипирования и презентации моделей. Аналоги Gradio:

- *Streamlit* — ещё один популярный фреймворк на Python для создания веб-приложений для анализа данных и ML. Более гибкий в плане построения кастомных интерфейсов и дашбордов.
- *Dash (от Plotly)* — мощная платформа для создания аналитических веб-приложений с визуализациями. Подходит для продвинутых BI-интерфейсов.
- *Voila* — превращает Jupyter Notebook в полноценное веб-приложение, скрывая сам код.
- *Panel* — библиотека для создания дашбордов и визуализаций на базе Bokeh и других библиотек.

Дообучение (fine-tuning) — это процесс адаптации уже обученной модели (обычно нейросети) к новой задаче или новому набору данных. Вместо того чтобы обучать модель с нуля, используется предобученная модель, в которую вносятся изменения только на отдельных слоях или на последнем этапе обучения. Fine-tuning особенно полезен, когда есть ограниченное количество данных, но доступна мощная предобученная модель, уже знакомая с «общими» признаками (например, текстами или изображениями).

*MLOps* (Machine Learning Operations) — это набор практик и инструментов для автоматизации и управления полным жизненным циклом моделей машинного обучения: от подготовки данных и обучения моделей до их деплоя, мониторинга и обновления.  

Он объединяет методы *DevOps*, *Data Engineering* и *машинного обучения*, чтобы упростить и ускорить переход от экспериментальных моделей к стабильным и масштабируемым решениям в продакшене.  

Цель MLOps — обеспечить воспроизводимость, автоматизацию, контроль версий и наблюдаемость в ML-проектах.

Наиболее популярные облачные платформы для MLOps включают:
- *Vertex AI (Google Cloud)* — платформа «всё-в-одном» для разработки, обучения, деплоя и мониторинга моделей машинного обучения. Имеет глубокую интеграцию с BigQuery, AutoML, Kubeflow Pipelines и GCS.
- *SageMaker (AWS)* — мощная платформа для MLOps в экосистеме AWS. Поддерживает автоматическое обучение (AutoML), управление экспериментами, деплой моделей и мониторинг, а также имеет встроенные инструменты для аннотации данных.
- *Azure Machine Learning* — платформа от Microsoft для обучения, тестирования и развертывания моделей с поддержкой MLOps через Azure DevOps и GitHub Actions. Подходит для корпоративных решений.
- *Databricks* — облачная среда, ориентированная на совместную работу с данными и ML. Встроенная поддержка MLflow позволяет управлять результатами экспериментов, версиями моделей и их продакшн-деплоем.
- *Kubeflow (в Kubernetes-кластерах)* — открытая платформа для MLOps, разворачиваемая в облаке или on-premises. Гибкая и мощная, однако её использование требует высокой технической подготовки.

*Пайплайн MLOps* — это автоматизированная последовательность шагов, которая охватывает весь процесс создания и эксплуатации модели машинного обучения. Он обеспечивает воспроизводимость, масштабируемость и контроль на всех этапах жизненного цикла модели.

Пайплайн обычно состоит из следующих этапов:
1. *Сбор и подготовка данных* — очистка, аугментация (добавление искусственно измененных образцов данных), разбиение на обучающую/тестовую выборки.
2. *Обучение модели* — запуск экспериментов, подбор гиперпараметров.
3. *Оценка качества* — метрики точности, проверка на валидационном наборе.
4. *Упаковка и регистрация модели* — сохранение модели и метаданных в реестре.
5. *Деплой* — развертывание модели в виде сервиса или API.
6. *Мониторинг и обновление* — отслеживание качества модели в продакшене, отклик на деградацию.

## Практическая часть

**План работы**
* Подготовка набора данных.
* Дообучение готовой модели нейронной сети.
* Развертывание приложения с моделью нейронной сети.

### Создание набора данных

1. Создайте на локальном компьютере каталог для проекта.

2. Откройте командную строку Windows и перейдите в каталог проекта:
    ```cmd
    cd <КАТАЛОГ ПРОЕКТА>
    ```
3. Создайте виртуальное окружение Python:
    ```cmd
    py -m venv venv
    ```
4. Активируйте виртуальное окружение:
    ```cmd
    venv\scripts\activate.bat
    ```
5. Установите необходимые библиотеки:
    ```cmd
    pip install aiohttp[speedups] duckduckgo-search
    ```
6. Создайте скрипт `prepare_data.py` с помощью кода в [гисте](https://gist.github.com/volodya-leveryev/99a1072b0086e41cc759ec28d458f4d5/).

7. Изучите код скрипта, внесите необходимые изменения и скачайте с его помощью фотографий 3 различных киноактеров.

8. Откройте скачанные файлы в проводнике, просмотрите скачанные фотографии и уберите:
    * повреждённые фото
    * фото с несколькими лицами
    * фото где плохо видно лицо
    * фото с лицом другого человека

9. Сожмите получившийся каталог `dataset` в архив формата `zip`.

### Обучение модели

1. Откройте сервис Google Colab ([colab.research.google.com](https://colab.research.google.com)) и авторизуйтесь с помощью своего Google-аккаунта.

2. Смените тип среды выполнения (`Runtime` → `Change runtime type` или `Среда выполнения` → `Сменить среду выполнения`) на `T4 GPU`.

3. Загрузите `dataset.zip` в хранилище среды выполнения. После загрузки файла выполните в ячейке:
    ```bash
    ! unzip dataset.zip
    ```

4. С помощью кода из файла `train.py` из [гисте](https://gist.github.com/volodya-leveryev/99a1072b0086e41cc759ec28d458f4d5/) выполните обучение модели.

5. Скачайте на локальный компьютер файл `model.pth`.

### Развёртывание приложения

1. Создайте на локальном компьютере скрипт `app.py` с помощью кода из [гисты](https://gist.github.com/volodya-leveryev/99a1072b0086e41cc759ec28d458f4d5/). Исправьте значение пременной `labels` так, чтобы в нем были указаны имена актеров из набора данных. Порядок следования имен должен соответствовать алфавитному порядку в каталоге `dataset`.

2. Создайте на локальном компьютере файл `requirements.txt` следующего содержания:
    ```text
    --index-url https://download.pytorch.org/whl/cpu
    torch
    torchvision
    ```

3. Создайте учетную запись (или войдите в существующую) на сайте [huggingface.co](https://huggingface.co). Если создаете новую учетную запись, то нужно подтвердить свой почтовый адрес.

4. Перейдите в раздел **Spaces** и создайте новое приложение нажав кнопку **+ New Space** со следующими настройками:
    * Space name: `lab17`.
    * Select the Space SDK: `Gradio`.
    * Остальные параметры оставьте без изменений.

5. После создания перейдите в раздел `Files`, выберите `+ Contribute` → `Upload files` и загрузите файлы:
    * `model.pth`
    * `app.py`
    * `requirements.txt`

6. После сборки Docker-контейнера и запуска приложения проверьте его работу.
