---
layout: default
title: Оглавление
---

# Практическая работа «PySpark»

## Цель работы

Проверить работу платформы PySpark.

## Ход работы

1. Подключиться к кластеру по протоколу SSH.

  * получить у преподавателя логин, ключ и адрес кластера
  * использовать клиент ssh (OpenSSH или PuTTY) для подключения к кластеру
  * после подключения определить
    - имя компьютера (команда `hostname`)
    - тип процессора (команда `head /proc/cpuinfo`)
    - объем ОЗУ (команда `free -h`)
    - объем файловых систем (команда `df -h`)
  * сделать скриншот

2. Подключиться к веб-интерфейсу HDFS и YARN

  * настроить динамический перенаправление TCP-портов в подключении SSH
  * настроить в браузере использование прокси SOCKS5
  * открыть в браузере веб-интерфейс HDFS
  * найти браузер файлов и сделать скриншот
  * открыть в браузере веб-интерфейс YARN
  * найти перечень заданий и сделать скриншот

3. Подготовить данные

через интерфейс командной строки:

  * создать каталог для входных данных (`mkdir <имя каталога>`)
  * создать текстовый файл (`nano <имя файла>`) и добавить в него текст
  * загрузить каталог в HDFS (`hadoop fs -put <имя каталога> <путь в HDFS>`)
  * сделать скриншот команды и её результата

4. Скомпилировать исходный код примера

  * создать файл с исходным кодом (см. Литературу)
  * скомпилировать исходный код
  * сделать скриншот команды и её результата
  * запустить задание
  * сделать скриншот команды и её результата
  * сделать скриншот переченя заданий в веб-интерфейса YARN
  * отобразить результат на экран (`hadoop fs -cat <имя файла с результатом>`)
  * сделать скриншот команды и её результата

## Литература

* [Динамическое перенаправление TCP-портов](https://erev0s.com/blog/ssh-local-remote-and-dynamic-port-forwarding-explain-it-i-am-five/#dynamic-port-forwarding)
* [Команды HDFS](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html)
* [Исходный код примера](https://hadoop.apache.org/docs/r3.3.4/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#Example:_WordCount_v1.0)
* [Как работать с PySpark](https://pythonru.com/biblioteki/pyspark-dlja-nachinajushhih)
