---
layout: default
title: Оглавление
---

# Введение

## Постановка проблемы

С чего все началось: Google нужно было индексировать данные для поиска по веб-страницам.

Что такое большие данные?

* такой объем данных, который не помещается в ОЗУ одного компьютера
* такой объем данных, который собирается быстрее чем один компьютер успевает их обрабатывать

Таким образом, для обработки больших данных необходимо распараллелить обработку данных на множестве компьютеров объединенных в кластер.

Особенности больших данных:

* конечный результат слабо зависит от одного элемента данных
* нерегулярная структура данных

Дополнительную сложность при работе большими данными представляет их хранение данных перед обработкой. Для этого можно использовать:

* Файлы — неудобно хранить метаданные, возможны проблемы с надежностью хранения, возможны проблемы со скоростью доступа
* Реляционные СУБД ([принципы ACID](https://ru.wikipedia.org/wiki/ACID)) — записывают данные медленнее чем нереляционные СУБД, масштабируются хуже чем нереляционные СУБД
* Нереляционные СУБД ([принципы BASE](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_CAP) — возможны проблемы с согласованностью данных

## Apache Hadoop

Hadoop — первая платформа для работы с большими данными.

Кластеры Hadoop строятся на недорогом аппаратном обеспечении (Commodity Hardware). Кластер Hadoop готов к выходу из строя небольшого количества вычислительных узлов.

Hadoop был создан в 2004 году в Google для решения задачи индексации HTML-страниц. Затем в 2007 году проект был передан фонду Apache для дальнейшего развития сообществом.

Для обработки данных в Hadoop применяется MapReduce — модель распределенных вычислений при которой:

* данные разделяются на большое количество одинаковых элементарных фрагментов
* элементарные фрагменты обрабатываются параллельно функциями типа **Map** на узлах кластера Hadoop
* результаты обработки элементарных фрагментов сводятся (редуцируются) в конечный результат функциями типа **Reduce**

При этом, разбиение исходных данных на порции для элементарных заданий, а также группировку сходных данных перед их сведения берет на себя платформа MapReduce.

Программисту остается написать на языке Java функции типа **Map** и **Reduce** и скомпилировать их в готовые к запуску модули в формате Jar.

Для запуска обработки данных пользователь должен создать задание в котором указывается исполняемый модуль в формате Jar и входные данные.

## Apache Hadoop YARN

[YARN](https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html) (Yet Another Resource Negotiator) — компонент Hadoop, который управляет очередностью запуска заданий и распределением заданий узлам кластера.

## Hadoop Distributed File System (HDFS)

Для хранения данных Hadoop использует файловую систему HDFS — Hadoop Distributed File System.

HDFS хорошо приспособлена для хранения больших файлов. Каждый файл разбивается на блоки одинакового размера (кроме последнего). Каждый блок может быть скопирован на несколько узлов кластера. Размер блока и коэффициент репликации (количество узлов, на которые должен быть скопирован каждый блок) определяются в настройках HDFS. По умолчанию используются блоки размером в 128 Мб и коэффициент избыточности равный трем.

Благодаря репликации обеспечивается устойчивость распределенной системы к отказам отдельных узлов. Файлы в HDFS могут быть записаны лишь однажды (модификация не поддерживается). Запись в файл в одно время может вести только один процесс.

Организация файлов в пространстве имён — традиционная иерархическая: есть корневой каталог, поддерживается вложение каталогов, в одном каталоге могут располагаться и файлы, и другие каталоги.

HDFS предусматривает наличие центрального узла имён (name node), хранящего метаданные файловой системы и метаинформацию о распределении блоков. Узлы кластера которые непосредственно хранят блоки файлов называются узлами данных (data node).

Узел имён отвечает за обработку операций уровня файлов и каталогов — открытие и закрытие файлов, манипуляция с каталогами. Узлы данных непосредственно отрабатывают операции по записи и чтению данных.

Узел имён и узлы данных снабжаются веб-серверами, отображающими текущий статус узлов и позволяющими просматривать содержимое файловой системы. Административные функции доступны из интерфейса командной строки.

Несмотря на то что HDFS изначально являлся неотъемлемой частью проекта, сегодня Hadoop поддерживает работу и с другими распределёнными файловыми системами. Например, в основном дистрибутиве реализована поддержка Amazon S3 и CloudStore.

С другой стороны, HDFS может использоваться не только для запуска MapReduce-заданий, но и как распределённая файловая система общего назначения. В частности, поверх неё реализована распределённая NoSQL-СУБД HBase.

## Развитие Hadoop

В процессе развития платформы Hadoop было создано большое количество высокоуровневых средств образующих своего рода экосистему:

* [Apache Hive](https://hive.apache.org/) — средство выполнения SQL-подобных запросов к данным
* [Cloudera Impala](https://www.cloudera.com/products/open-source/apache-hadoop/impala.html) — средство выполнения SQL-подобных запросов к данным
* [Apache Pig](https://pig.apache.org/) — высокоуровневый скриптовый язык для обработки данных
* [Apache Mahout](https://mahout.apache.org/) — Machine Learning поверх MapReduce
* [Apache Sqoop](https://sqoop.apache.org/) — импорт-экспорт данных из / в базы данных
* [Apache Kafka](https://kafka.apache.org/) — потоковая обработка данных
* [Apache Flume](https://flume.apache.org/) — средство для сбора и обработки логов
* [Apache Zookeeper](https://zookeeper.apache.org/) — средство координации работы узлов
* [Apache Oozie](https://oozie.apache.org/) — средство организации рабочего процесса и управления очередью заданий
* [Apache Ambari](https://ambari.apache.org/) — веб-интерфейс для управления и мониторинга
* [Cloudera Hue](https://www.cloudera.com/products/open-source/apache-hadoop/hue.html) — удобный веб-интерфейс для работы с кластером Hadoop
* [Apache HBase](https://hbase.apache.org/) — средство доступа к данным в виде widecolumn NoSQL БД
* и другие

Принципиально новым этапом в развитии Hadoop стал [Apache Spark](https://spark.apache.org/) — платформа вычислений, которая ускоряет вычисления MapReduce благодаря тому, что хранит данные промежуточных результатов вычислений в ОЗУ узлов, а не в HDFS.

Платформа Spark также может работать в контейнерах под управлением [Kubernetes](https://kubernetes.io/) и на кластерах [Apache Mesos](http://mesos.apache.org/). Кроме того, Spark может управлять кластером самостоятельно.

На базе Spark работают несколько высокоуровневых программных средств:

* [Spark SQL](https://spark.apache.org/sql/) — средство выполнения SQL-подобных запросов к данным
* [Spark Streaming](https://spark.apache.org/streaming/) — средство потоковой обработки данных
* [MLlib](https://spark.apache.org/mllib/) — средство для машинного обучения
* [GraphX](https://spark.apache.org/graphx/) — средство для вычислений на графах

Программирование на Spark осуществляется на:

* Java
* Scala
* Python

## Современные тренды

Современные тренды:

* развертывание компонентов Hadoop в Kubernetes
* хранение и обработка больших данные в облачных сервисах

Облачные решения:

* AWS
  - [AWS Redshift](https://aws.amazon.com/redshift/) — хранилище данных
  - [AWS Athena](https://aws.amazon.com/athena/) — SQL запросы к данным в AWS S3
  - [AWS Elastic MapReduce (EMR)](https://aws.amazon.com/emr/) — Apache Spark / Hadoop
  - [AWS Kinesis](https://aws.amazon.com/kinesis/) — потоковая обработка данных
* Microsoft Azure
  - [Microsoft Azure Storage](https://azure.microsoft.com/en-us/services/storage/) — хранилище данных
  - [Microsoft Azure HDInsight](https://azure.microsoft.com/en-us/services/hdinsight/) — Apache Spark / Hadoop
  - [Microsoft Azure Event Hub](https://azure.microsoft.com/en-us/services/event-hubs/) — потоковая обработка данных
* Google Cloud Platform
  - [Google Cloud BigQuery](https://cloud.google.com/bigquery) — хранилище данных
  - [Google Cloud Dataproc](https://cloud.google.com/dataproc) — Apache Spark / Hadoop
  - [Google Cloud Dataflow](https://cloud.google.com/dataflow) — потоковая обработка данных
* IBM
* Ali Baba
* Yandex
* другие

## ElasticStack

Компоненты:

* [ElasticSearch](https://ru.wikipedia.org/wiki/Elasticsearch) — распределенная поисковая система
* Logstash — система сбора и обработки логов
* [Kibana](https://ru.wikipedia.org/wiki/Kibana) — платформа аналитики и визуализации
* Beats — коллекция легковесных средств экспорта данных

Часть программных компонентов имеет открытый исходный код.

На базе ElasticStack создано большое количество производных продуктов.

В настоящий момент активно развиваются облачные сервисы на базе продуктов ElasticStack.
